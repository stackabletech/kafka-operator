= Stackable Operator for Apache Kafka
:description: The Stackable Operator for Apache Superset is a Kubernetes operator that can manage Apache Kafka clusters. Learn about its features, resources, dependencies and demos, and see the list of supported Kafka versions.
:keywords: Stackable Operator, Apache Kafka, Kubernetes, operator, SQL, engineer, broker, big data, CRD, StatefulSet, ConfigMap, Service, Druid, ZooKeeper, NiFi, S3, demo, version

The Stackable Operator for Apache Kafka is an operator that can deploy and manage https://kafka.apache.org/[Apache Kafka] clusters on Kubernetes. 
// what is Kafka?
Kafka is a distributed event streaming platform ... TODO


== Getting started

Follow the xref:kafka:getting_started/index.adoc[] which will guide you through installing The Stackable Kafka and ZooKeeper Operators, setting up ZooKeeper and Kafka and testing your Kafka using kcat.

== Resources

The _KafkaCluster_ custom resource defines all your Kafka cluster configuration. It defines a single `broker` xref:concepts:roles-and-role-groups.adoc[role].

image::kafka_overview.drawio.svg[A diagram depicting the Kubernetes resources created by the operator.]

For every xref:concepts:roles-and-role-groups.adoc#_role_groups[role group] in the `broker` role the Operator creates a StatefulSet. Multiple Services are created, one at role level, one per role group as well as one for every individual Pod, to allow accessing the whole Kafka cluster, parts of it or even individual brokers.

For every StatefulSet (role group) a ConfigMap is deployed containing a `log4j.properties` file for xref:usage-guide/logging.adoc[logging] configuration and a `server.properties` file containing the whole Kafka configuration which is derived from the KafkaCluster resource.

== Dependencies

Kafka currently requires Apache ZooKeeper for coordination purposes.

NOTE: This will change https://cwiki.apache.org/confluence/display/KAFKA/KIP-500[in the future].

== Connections to other products

Input from NiFi

Output to Druid

== [[demos]]Demos

xref:stackablectl::index.adoc[] supports installing xref:stackablectl::demos/index.adoc[] with a single command. The demos are complete data piplines which showcase multiple components of the Stackable platform working together and which you can try out interactively. Both demos below include inject data into Kafka using NiFi and use Druid as a destination for the Kafka topics.

=== Waterlevel Demo

The xref:stackablectl::demos/nifi-kafka-druid-water-level-data.adoc[] demo uses data from https://www.pegelonline.wsv.de/webservice/ueberblick[PEGELONLINE] to visualize water levels in rivers and coastal regions of Germany from historic and real time data. 

=== Earthquake Demo

The xref:stackablectl::demos/nifi-kafka-druid-earthquake-data.adoc[] demo ingests https://earthquake.usgs.gov/[earthquake data] into a similar pipeline as is used in the waterlevel demo.


== Supported Versions

The Stackable Operator for Apache Kafka currently supports the following versions of Kafka:

include::partial$supported-versions.adoc[]
