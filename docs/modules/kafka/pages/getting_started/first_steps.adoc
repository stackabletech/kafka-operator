= First steps
:description: Deploy and verify a Kafka cluster on Kubernetes with Stackable Operators, including ZooKeeper setup and data testing using kcat.
:kcat-install: https://github.com/edenhill/kcat#install

After going through the xref:getting_started/installation.adoc[] section and having installed all the operators, you now deploy a Kafka cluster and the required dependencies.
Afterward you can <<_verify_that_it_works, verify that it works>> by producing test data into a topic and consuming it.

== Setup

Two things need to be installed to create a Kafka cluster:

* A ZooKeeper instance for internal use by Kafka
* The Kafka cluster itself

Create them in this order, each one is created by applying a manifest file.
The operators you just installed then create the resources according to the manifest.

=== ZooKeeper

Create a file named `zookeeper.yaml` with the following content:

[source,yaml]

----
include::example$getting_started/zookeeper.yaml[]
----

and apply it:

[source,bash]
----
include::example$getting_started/getting_started.sh[tag=install-zookeeper]
----

Create a file `kafka-znode.yaml` with the following content:

[source,yaml]
----
include::example$getting_started/kafka-znode.yaml[]
----

and apply it:

[source,bash]
----
include::example$getting_started/getting_started.sh[tag=install-znode]
----

=== Kafka

Create a file named `kafka.yaml` with the following contents:

[source,yaml]
----
include::example$getting_started/kafka.yaml[]
----

and apply it:

----
include::example$getting_started/getting_started.sh[tag=install-kafka]
----

This creates the actual Kafka instance.

== Verify that it works

Next you produce data into a topic and read it via {kcat-install}[kcat].
Depending on your platform you may need to replace `kafkacat` in the commands below with `kcat`.

First, make sure that all the Pods in the StatefulSets are ready:

[source,bash]
----
kubectl get statefulset
----

The output should show all pods ready:

----
NAME                                 READY   AGE
simple-kafka-broker-default          3/3     5m
simple-zk-server-default             3/3     7m
----

Then, create a port-forward for the Kafka Broker:

----
include::example$getting_started/getting_started.sh[tag=port-forwarding]
----

Create a file containing some data:

----
include::example$getting_started/getting_started.sh[tag=kcat-create-data]
----

Write that data:

----
include::example$getting_started/getting_started.sh[tag=kcat-write-data]
----

Read that data:

----
include::example$getting_started/getting_started.sh[tag=kcat-read-data]
----

Check the content:

----
include::example$getting_started/getting_started.sh[tag=kcat-check-data]
----

And clean up:

----
include::example$getting_started/getting_started.sh[tag=kcat-cleanup-data]
----

You successfully created a Kafka cluster and produced and consumed data.

== What's next

Have a look at the xref:usage.adoc[] page to find out more about the features of the Kafka Operator.
