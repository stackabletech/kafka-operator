= First steps

After going through the xref:installation.adoc[] section and having installed all the operators, you will now deploy a Kafka cluster and the required dependencies. Afterwards you can <<_verify_that_it_works, verify that it works>> by producing test data into a topic and consuming it.

== Setup

Two things need to be installed to create a Kafka cluster:

* A ZooKeeper instance for internal use by Kafka
* The Kafka cluster itself

We will create them in this order, each one is created by applying a manifest file. The operators you just installed will then create the resources according to the manifest.

=== ZooKeeper

Create a file named `zookeeper.yaml` with the following content:

[source,yaml]

----
include::example$code/zookeeper.yaml[]
----

and apply it:

[source,bash]
----
include::example$code/getting-started.sh[tag=install-zookeeper]
----

Create a file `kafka-znode.yaml` with the following content:

[source,bash]
----
include::example$code/kafka-znode.yaml[]
----

and apply it:

[source,bash]
----
include::example$code/getting-started.sh[tag=install-znode]
----

=== Kafka

Create a file named `kafka.yaml` with the following contents:

[source,yaml]
----
include::example$code/kafka.yaml[]
----

and apply it:

----
include::example$code/getting-started.sh[tag=install-kafka]
----

This will create the actual Kafka instance.

== Verify that it works

Next you will produce data into a topic and read it via https://github.com/edenhill/kcat#install[kcat]. Depending on your platform you may need to replace `kafkacat` in the commands below with `kcat`.

First, make sure that all the Pods in the StatefulSets are ready:

[source,bash]
----
kubectl get statefulset
----

The output should show all pods ready:

----
NAME                                 READY   AGE
simple-kafka-broker-default          3/3     5m
simple-zk-server-default             3/3     7m
----

Then, create a port-forward for the Kafka Broker:

----
include::example$code/getting-started.sh[tag=port-forwarding]
----

Create a file containing some data:

----
include::example$code/getting-started.sh[tag=kcat-create-data]
----

Write that data:

----
include::example$code/getting-started.sh[tag=kcat-write-data]
----

Read that data:

----
include::example$code/getting-started.sh[tag=kcat-read-data]
----

Check the content:

----
include::example$code/getting-started.sh[tag=kcat-check-data]
----

And clean up:

----
include::example$code/getting-started.sh[tag=kcat-cleanup-data]
----

You successfully created a Kafka cluster and produced and consumed data.

== What's next

Have a look at the xref:ROOT:usage.adoc[] page to find out more about the features of the Kafka Operator.
